{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPGPr6Y/lcMpHOVIX1y6tFG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Fulmenius/Statistics/blob/main/statistics_maximal_likelihood.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Maximal likelihood estimation"
      ],
      "metadata": {
        "id": "y1FVPYwiSIlN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Problem 1\n",
        "Consider the following experiment, which simulates user behavior when searching for information in a search engine:\n",
        "\n",
        "The user sequentially views documents until they find the necessary information or get tired. The probability that the user will find the information in the document number $i$ is equal to $p$, the probability that they will not find the information in the document $i$ is equal to $(1-p)$. The probability $p$ does not depend on the document number. The probability that the user will get tired after viewing the $i$-th document is equal to $g$, accordingly, they will continue searching with a probability of $(1âˆ’g)$. This probability does not depend on the number of the viewed document. The user always views at least one document. Moreover, we know whether the user found the information or not ($F$ - found, $N$ - not found).\n",
        "\n",
        "Observation: the number of viewed documents and the fact of \"whether the information is found or not\".\n",
        "\n",
        "For example,\n",
        "\n",
        "   *  An observation of '2 F' means that the user viewed the first document, did not find the information in it, didn't get tired, viewed the second document, and found the information in it.\n",
        "   *  An observation of '1 N' means that the user viewed the first document, did not find the information in it and got tired, thus stopped viewing the documents.\n",
        "\n",
        "Given a file with string of the format `k X`, where `k` is and integer and `X` can be `F` or `G`, find the maximal likelihood estimates for the values of $p$ and $g$."
      ],
      "metadata": {
        "id": "lIDL-_1WMG2h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Solution\n",
        "Let's find the log-likelihood function and take its gradient to find potential extremal points.\n",
        "The observation `n F` has the probability $(1-p)^{n-1} p (1-g)^{n-1}$, because the user does not find the information they need $n-1$ times and does find it once, while not abrupting their search $n-1$ times.\n",
        "\n",
        "Analogously, if the observation is `m N`, the user does not find the document $m$ times, does not get tired $m-1$ times and does get tired $1$ times, so the probability of such event is $(1-p)^{m}(1-g)^{m-1}g$.\n",
        "\n",
        "The total likelihood function $L$ is the product of probabilities of all individual observations, so in $\\ln L$ we have the sum of the form\n",
        "$$A \\ln(1-p) + B \\ln p + C \\ln (1-g) + D \\ln g$$, where, by the properties of the logarithm\n",
        "$$A = \\left[\\sum_{i} (n_i-1) + \\sum_{j}m_j \\right]$$\n",
        "$$B = \\sum_i 1$$\n",
        "$$C = \\left[ \\sum_i (n_i -1) + \\sum_j (m_j - 1) \\right]$$\n",
        "$$D = \\sum_j 1$$\n",
        "\n",
        "where $i$ enumerates entries with `F` and $j$ enumerates entries with `N`. Taking the gradient of this sum and equating it to zero, we find the only solution with\n",
        "$$p = \\frac{B}{A+B}$$\n",
        "\n",
        "$$g= \\frac{D}{D+C}$$\n",
        "\n",
        "Let's encode this:"
      ],
      "metadata": {
        "id": "34L2RwjLM53K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "A = 0\n",
        "B = 0\n",
        "C = 0\n",
        "D = 0\n",
        "\n",
        "with open('sample_2_4.txt', 'r') as read:\n",
        "  for line in read:\n",
        "    k, X = line.split()\n",
        "    k = int(k)\n",
        "    if X == 'F':\n",
        "      A += k-1\n",
        "      B += 1\n",
        "      C += k-1\n",
        "    else:\n",
        "      A += k\n",
        "      C += k-1\n",
        "      D += 1\n",
        "\n",
        "print('A = {}, B = {}, C = {}, D = {}'.format(A, B, C, D))\n",
        "\n",
        "p = B/(A+B)\n",
        "g = D/(D+C)\n",
        "print('p = {}, g = {}'.format(p, g))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "illpyvOtQejT",
        "outputId": "fd19302a-c015-490e-9af4-b5fe9ddbe4c1"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A = 97, B = 78, C = 75, D = 22\n",
            "p = 0.44571428571428573, g = 0.2268041237113402\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Problem 2\n",
        "\n",
        "A distribution has density function $f(x)=\\theta(-x(x-1))ax^{a-1}$, where $\\theta$ denotes the \"step\" function which equals $0$ if its argument is less than zero, $1/2$ if it equals zero, and $1$ otherwise. Find the maximal likelihood and method of moments estimation of $a$ for a given sample. $ a > 1$."
      ],
      "metadata": {
        "id": "Ci8V16b7SVgE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Solution\n",
        "The likelihood function is $$L(a, X_{[n]})=\\prod_{i=1}^n aX_i^{a-1}$$ where $X_i$ is the $i$'th observation from the sample of size $n$. The log-likelihood function is thus\n",
        "$$\\sum_{i=1}^n (\\ln a + (a-1)\\ln X_i)$$\n",
        "and its derivative w.r.t. $a$ is\n",
        "$$\\sum_{i=1}^{n}\\left( \\frac{1}{a} + \\ln X_i \\right)=\\frac{n}{a} + \\sum_{i=1}^{n} \\ln X_i $$\n",
        "which gives\n",
        "$$a=\\frac{-n}{\\sum_{i=1}^{n}\\ln X_i}$$\n",
        "\n",
        "The first moment of the distribution is\n",
        "$$\\int_{0}^{1} a x^{a}dx =\\frac{a}{a+1}$$\n",
        "from which we can estimate the parameter $a$ as\n",
        "$$\\frac{\\bar{X}_{[n]}}{1- \\bar{X}_{[n]}}$$\n",
        "where $\\bar{X}_{[n]}$ is the sample mean. For example, for the sample `0.4, 0.7, 0.9`"
      ],
      "metadata": {
        "id": "lQh0T1LfULol"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from math import log\n",
        "import numpy as np\n",
        "\n",
        "sample = [0.4, 0.7, 0.9]\n",
        "\n",
        "max_likelihood_a = -len(sample)/(sum(list(map(log, sample))))\n",
        "method_of_moments_a = np.mean(sample)/(1 - np.mean(sample))\n",
        "\n",
        "print('ML_a = {}, MM_a = {}'.format(max_likelihood_a, method_of_moments_a))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ewTyYU-zRNCn",
        "outputId": "3a0f93c8-1245-4cc5-b0f3-13de47e94c33"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ML_a = 2.17655299490385, MM_a = 1.9999999999999998\n"
          ]
        }
      ]
    }
  ]
}